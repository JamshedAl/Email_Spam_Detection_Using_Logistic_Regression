{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a28cb58fdcc14bcfa6573954af5e3c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2912a6a3a7244d979a45178e24d1853a",
              "IPY_MODEL_f6233c7a2311425da61e0dca6f0120f8",
              "IPY_MODEL_733c7960da92415589df4d9591a3ca94"
            ],
            "layout": "IPY_MODEL_050171291cb74f88b27a478f52f87363"
          }
        },
        "2912a6a3a7244d979a45178e24d1853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a69220d6922342109b7091f9f2525cf3",
            "placeholder": "​",
            "style": "IPY_MODEL_a3ff8fb2eb6749b0aa7cc2d7911e7308",
            "value": "Map: 100%"
          }
        },
        "f6233c7a2311425da61e0dca6f0120f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cee1c8a2bc54f24b118b7f9eef3db12",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1059f51016504bc9abae046cfa239e6a",
            "value": 1000
          }
        },
        "733c7960da92415589df4d9591a3ca94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377dcd4afc8c457887fd0a2f4b56f0ce",
            "placeholder": "​",
            "style": "IPY_MODEL_3a5b238bb3ca49dc936c5b9d3faaa5ce",
            "value": " 1000/1000 [00:00&lt;00:00, 5546.22 examples/s]"
          }
        },
        "050171291cb74f88b27a478f52f87363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69220d6922342109b7091f9f2525cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ff8fb2eb6749b0aa7cc2d7911e7308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cee1c8a2bc54f24b118b7f9eef3db12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1059f51016504bc9abae046cfa239e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377dcd4afc8c457887fd0a2f4b56f0ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5b238bb3ca49dc936c5b9d3faaa5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad80f403b60040d891582ea164ab1d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b080c3febf241b9893bce9a288ece8c",
              "IPY_MODEL_bdb3c3a5dc6942a6988b982f9ce52729",
              "IPY_MODEL_4d0404dcb07642b283a413e570f2d983"
            ],
            "layout": "IPY_MODEL_59111ef992694e158c530f06d4c17b2c"
          }
        },
        "9b080c3febf241b9893bce9a288ece8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28d8dd64bf0a414b84051088de39deb5",
            "placeholder": "​",
            "style": "IPY_MODEL_808a129dbf5342e3b2a6922ffa85e0d3",
            "value": "Map: 100%"
          }
        },
        "bdb3c3a5dc6942a6988b982f9ce52729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0cda1b1bf93401891e7017252165694",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c715da8624f34520869f7657c3c71ef2",
            "value": 100
          }
        },
        "4d0404dcb07642b283a413e570f2d983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a8da6e086494939b2311596579a78d9",
            "placeholder": "​",
            "style": "IPY_MODEL_db21854fd98a44d4bfeb892660ad7d5c",
            "value": " 100/100 [00:00&lt;00:00, 1210.59 examples/s]"
          }
        },
        "59111ef992694e158c530f06d4c17b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d8dd64bf0a414b84051088de39deb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808a129dbf5342e3b2a6922ffa85e0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0cda1b1bf93401891e7017252165694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c715da8624f34520869f7657c3c71ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a8da6e086494939b2311596579a78d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db21854fd98a44d4bfeb892660ad7d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64434a20169b4c98b2a6bae5fe0cdfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_501fcd0e4555487095abcb592511683c",
              "IPY_MODEL_7b4904586b6849a29cf19ac3b086b508",
              "IPY_MODEL_22ef9615e7534e6ebb3a95daa0c3ac1d"
            ],
            "layout": "IPY_MODEL_e6010267999843d19f2af39acc8b3fd4"
          }
        },
        "501fcd0e4555487095abcb592511683c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec800871c5ac4351b64534f4f53bcbf4",
            "placeholder": "​",
            "style": "IPY_MODEL_e2c84d4eb26b4954842b511f7d0125ce",
            "value": "Map: 100%"
          }
        },
        "7b4904586b6849a29cf19ac3b086b508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d18bc23a6c4fdd8e2d4e0b6940f2b6",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da29f0bccf85496e86e97f455d012eb1",
            "value": 43
          }
        },
        "22ef9615e7534e6ebb3a95daa0c3ac1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6acbb36f71d6479db2b3085c0e9547d8",
            "placeholder": "​",
            "style": "IPY_MODEL_d0dca114fde94abaa689f9ea06c8f005",
            "value": " 43/43 [00:00&lt;00:00, 769.97 examples/s]"
          }
        },
        "e6010267999843d19f2af39acc8b3fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec800871c5ac4351b64534f4f53bcbf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c84d4eb26b4954842b511f7d0125ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55d18bc23a6c4fdd8e2d4e0b6940f2b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da29f0bccf85496e86e97f455d012eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6acbb36f71d6479db2b3085c0e9547d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dca114fde94abaa689f9ea06c8f005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamshedAl/Email_Spam_Detection_Using_Logistic_Regression/blob/main/Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will see how to **fine-tune** one of the **hugging-face Transformers mode**l for translating **Urdu** to **English** language."
      ],
      "metadata": {
        "id": "go7OXWrQLlND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages"
      ],
      "metadata": {
        "id": "sI9uXAlCK3tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "Fsa5ZKoCK5iI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dTGcmnOU0_K",
        "outputId": "d977f93a-f03b-488e-ff7c-32b363558a9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM3a7WmrU4MX",
        "outputId": "fc6d9ecf-255b-432b-ede8-c87b51ca2210"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "Og0jduzALM2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5X2MpFoyA1f",
        "outputId": "214673c4-c4a6-40b0-b382-cabfe28d0e74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEpX5VLOVf-p",
        "outputId": "0e022eea-80ac-44bb-fc63-39784e1e79da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import datasets\n",
        "from datasets import Dataset, load_metric\n",
        "from google.colab import drive\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHWn8Q6zLKAL",
        "outputId": "0ee073d0-d54c-4ba9-c643-efdb4acfd133"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.35.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model Checkpoint"
      ],
      "metadata": {
        "id": "h-HS9LihL6dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-mt-ur-en\""
      ],
      "metadata": {
        "id": "JDXhux0XLQxV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Drive"
      ],
      "metadata": {
        "id": "LC1BqNC4M-PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/fine_tuning_ur_en_machine_translation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b33rXsGvNA-g",
        "outputId": "954aa744-fa7a-4732-8c12-f6d8dfb3f1e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/fine_tuning_ur_en_machine_translation/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Current Working Directory"
      ],
      "metadata": {
        "id": "KFiK7xzBKFgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "kf1fPPNolTDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "my_dir = os.getcwd() + '/'\n",
        "print(my_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjKDDyGKEPH",
        "outputId": "f3317cba-f4bd-4b41-98f0-d8ea333d87c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "KUh7Ia6oMLaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to translation file\n",
        "path_to_data = '/content/drive/MyDrive/urd.txt'\n",
        "\n",
        "# Read file\n",
        "translation_file = open(path_to_data,\"r\", encoding='utf-8')\n",
        "raw_data = translation_file.read()\n",
        "translation_file.close()\n",
        "\n",
        "# Parse data\n",
        "raw_data = raw_data.split('\\n')\n",
        "ur_en_pairs = [sentence.split('\\t') for sentence in  raw_data]\n",
        "del(ur_en_pairs[1143])"
      ],
      "metadata": {
        "id": "3hwJVuiIM48O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Custom DataSet"
      ],
      "metadata": {
        "id": "6TQ3Kmiekj8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = ur_en_pairs[:1000]\n",
        "validation_dataset = ur_en_pairs[1000:1100]\n",
        "testing_dataset = ur_en_pairs[1100:]"
      ],
      "metadata": {
        "id": "85PDdNNVto_d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict = [{'ur': i[1], 'en': i[0]} for i in training_dataset]\n",
        "test_dict = [{'ur': i[1], 'en': i[0]} for i in testing_dataset]\n",
        "validate_dict = [{'ur': i[1], 'en': i[0]} for i in validation_dataset]"
      ],
      "metadata": {
        "id": "lAL9LqoRXpzB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict = {'translation': train_dict}\n",
        "test_dict = {'translation': test_dict}\n",
        "validate_dict = {'translation': validate_dict}"
      ],
      "metadata": {
        "id": "RYC6qPSUcfhT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_dict(train_dict)\n",
        "test_dataset = Dataset.from_dict(test_dict)\n",
        "validate_dataset = Dataset.from_dict(validate_dict)\n"
      ],
      "metadata": {
        "id": "qE2B41dCgPZG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset = datasets.DatasetDict({\"train\":train_dataset, \"validation\":validate_dataset, \"test\":test_dataset})"
      ],
      "metadata": {
        "id": "B2sng-tuj876"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset"
      ],
      "metadata": {
        "id": "IqrjTyJ1kCyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f70af9-afd6-440a-8335-8457b7f7aa33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 43\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset['train'][855:865]"
      ],
      "metadata": {
        "id": "JtUFSO3MLy27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7070f0d5-2296-4e3c-bdfa-24707aa0062a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': [{'en': \"You don't need to go in such a hurry.\",\n",
              "   'ur': 'تمھیں اتنی جلدی جانے کی ضرورت نہیں ہے۔'},\n",
              "  {'en': 'Your mother will be back before long.',\n",
              "   'ur': 'تمہاری امی بس آتی ہونگی۔'},\n",
              "  {'en': 'Your mother will be back before long.',\n",
              "   'ur': 'تمہاری ماں بس راستے میں ہو گی۔'},\n",
              "  {'en': 'All of us were busy cleaning the room.',\n",
              "   'ur': 'ہم سارے کمرے کی صفائی کرنے میں مصروف تھے۔'},\n",
              "  {'en': 'All you have to do is sweep the floor.',\n",
              "   'ur': 'تمہیں صرف زمین کی صفائی کرنی ہے۔'},\n",
              "  {'en': 'Different people have different ideas.',\n",
              "   'ur': 'مختلف لوگوں کے مختلف خیالات ہیں۔'},\n",
              "  {'en': 'English is studied all over the world.',\n",
              "   'ur': 'انگریزی پوری دنیا میں پڑھای جاتی ہے۔'},\n",
              "  {'en': 'Everyone was listening very carefully.',\n",
              "   'ur': 'سارے بڑے غور سے سن رہے تھے۔'},\n",
              "  {'en': 'He does not take care of his children.',\n",
              "   'ur': 'وہ اپنے بچوں کا خیال نہیں کرتا۔'},\n",
              "  {'en': 'I have a lot of passwords to remember.',\n",
              "   'ur': 'مجھے کافی زیادہ پاسورڈس یاد دکھنے پڑتے ہے۔'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a sense of how the data looks like, the following function will show some examples picked randomly in the dataset."
      ],
      "metadata": {
        "id": "06qO-s-zrH2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=5):\n",
        "\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "\n",
        "    picks = []\n",
        "\n",
        "    for _ in range(num_examples):\n",
        "\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))\n",
        "\n",
        "show_random_elements(final_dataset[\"train\"])"
      ],
      "metadata": {
        "id": "eINunKmdLz_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b2eb0faf-a7ab-49e4-fb99-9ca10dd1e0e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'en': 'All of us were busy cleaning the room.', 'ur': 'ہم سارے کمرے کی صفائی کرنے میں مصروف تھے۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'en': 'She's a frequent visitor to this country.', 'ur': 'وہ اس ملک میں آتی جاتی رہتی ہے۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'en': 'Tom is only a beginner.', 'ur': 'ٹام نے ابھی ابتدا کی ہے۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'en': 'Paris is the capital of France.', 'ur': 'پیرس فرانس کا دارلخلافہ ہے۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'en': 'You need to study more.', 'ur': 'تمھیں زیادہ پڑھنا چاہئیے۔'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use **metric** to evaluation (to compare our model to the benchmark). This can be easily done with the functions **load_metric**."
      ],
      "metadata": {
        "id": "p8TxB0thuR3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacrebleu"
      ],
      "metadata": {
        "id": "JFacWkfaWMZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b54bb7-e7f5-47a1-e809-354903704bc6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "tppHVEymL0VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ad2dde-0732-41bc-ded4-f9358631fee2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-aede95515358>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"sacrebleu\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.0/metrics/sacrebleu/sacrebleu.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric"
      ],
      "metadata": {
        "id": "x8yWaOuFL0dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c722a437-cb44-4582-c889-b8db5c0d92e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
              "Produces BLEU scores along with its sufficient statistics\n",
              "from a source against one or more references.\n",
              "\n",
              "Args:\n",
              "    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n",
              "    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n",
              "    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n",
              "        - `'none'`: no smoothing\n",
              "        - `'floor'`: increment zero counts\n",
              "        - `'add-k'`: increment num/denom by k for n>1\n",
              "        - `'exp'`: exponential decay\n",
              "    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n",
              "    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n",
              "        - `'none'`: No tokenization.\n",
              "        - `'zh'`: Chinese tokenization.\n",
              "        - `'13a'`: mimics the `mteval-v13a` script from Moses.\n",
              "        - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n",
              "        - `'char'`: Language-agnostic character-level tokenization.\n",
              "        - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n",
              "    lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n",
              "    force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n",
              "    use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n",
              "\n",
              "Returns:\n",
              "    'score': BLEU score,\n",
              "    'counts': Counts,\n",
              "    'totals': Totals,\n",
              "    'precisions': Precisions,\n",
              "    'bp': Brevity penalty,\n",
              "    'sys_len': predictions length,\n",
              "    'ref_len': reference length,\n",
              "\n",
              "Examples:\n",
              "\n",
              "    Example 1:\n",
              "        >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
              "        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
              "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
              "        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
              "        >>> print(list(results.keys()))\n",
              "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
              "        >>> print(round(results[\"score\"], 1))\n",
              "        100.0\n",
              "\n",
              "    Example 2:\n",
              "        >>> predictions = [\"hello there general kenobi\",\n",
              "        ...                 \"on our way to ankh morpork\"]\n",
              "        >>> references = [[\"hello there general kenobi\", \"hello there !\"],\n",
              "        ...                 [\"goodbye ankh morpork\", \"ankh morpork\"]]\n",
              "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
              "        >>> results = sacrebleu.compute(predictions=predictions,\n",
              "        ...                             references=references)\n",
              "        >>> print(list(results.keys()))\n",
              "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
              "        >>> print(round(results[\"score\"], 1))\n",
              "        39.8\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can call its **compute method** with your **predictions** and **labels**, which need to be **list of decoded strings** (list of list for the labels):"
      ],
      "metadata": {
        "id": "3MNkQ5jPu1jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_preds = [\"سنو ذرا\", \"hello there\"]\n",
        "fake_labels = [[\"سنو ذرا\"], [\"hello there\"]]\n",
        "metric.compute(predictions=fake_preds, references=fake_labels,)"
      ],
      "metadata": {
        "id": "NMXrJInuL0lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d934990a-31a0-45e7-cc7b-395d9782ad95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.0,\n",
              " 'counts': [4, 2, 0, 0],\n",
              " 'totals': [4, 2, 0, 0],\n",
              " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
              " 'bp': 1.0,\n",
              " 'sys_len': 4,\n",
              " 'ref_len': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing (Tokenization) the dataset"
      ],
      "metadata": {
        "id": "thHiCmGMvLKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a **Transformers Tokenizer** which will (as the name indicates) **tokenize the inputs** (including **converting the tokens to their corresponding IDs** in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
        "\n",
        "To do all of this, we **instantiate our tokenizer with the AutoTokenizer.from_pretrained method**, which will ensure:\n",
        "\n",
        "we get a **tokenizer** that **corresponds** to the **model architecture** we want to use, we download the vocabulary used when pretraining this specific checkpoint. That vocabulary will be cached, so it's not downloaded again the next time we run the cell.\n",
        "\n",
        "If you downloaded the model manually, you can provide model present directory instead of model_checkpoint."
      ],
      "metadata": {
        "id": "gbfzwB8GvxB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "GVrqkxtcL0xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e906ed-dd0e-4831-a189-13ee579a2d2c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(my_dir+\"save_tokenizer\")"
      ],
      "metadata": {
        "id": "9VXepCt_JEmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28c511b-0e03-470f-a9cd-5816c4f5fe21"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/save_tokenizer/tokenizer_config.json',\n",
              " '/content/save_tokenizer/special_tokens_map.json',\n",
              " '/content/save_tokenizer/vocab.json',\n",
              " '/content/save_tokenizer/source.spm',\n",
              " '/content/save_tokenizer/target.spm',\n",
              " '/content/save_tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('./save_tokenizer/')"
      ],
      "metadata": {
        "id": "UZ3yfmmWEmvG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can directly call this tokenizer on one sentence or a pair of sentences:"
      ],
      "metadata": {
        "id": "0lE4aAVIK1s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
      ],
      "metadata": {
        "id": "2uArHXrsL00_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd949340-8c98-4d78-fb60-2f73d7ba1aeb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[56936, 9004, 2, 19741, 2889, 73, 4695, 73, 66, 7061, 15423, 67, 0], [4117, 15061, 66, 22, 73, 55163, 3565, 73, 66, 7061, 15423, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare the **targets for our model**, we need to tokenize them inside the **as_target_tokenizer** context manager. This will make sure the **tokenizer uses the special tokens** corresponding to the targets:"
      ],
      "metadata": {
        "id": "a7Ycf-zKLf1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
      ],
      "metadata": {
        "id": "ldpu2d2NL04v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996d6eac-1caf-4726-db94-469fcbb086cf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[20475, 2, 140, 155, 7166, 67, 0], [416, 22, 474, 7166, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Or\")\n",
        "\n",
        "tgt_text = [\"Hello, this one sentence!\", \"This is another sentence.\"],\n",
        "print(tokenizer(text_target = tgt_text))"
      ],
      "metadata": {
        "id": "0FzHDh5PL08K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b88041-62fb-41d4-9ac4-230cfa37b34c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Or\n",
            "{'input_ids': [[20475, 2, 140, 155, 7166, 67, 416, 22, 474, 7166, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then write the **function** that will **preprocess our samples**. We just feed them to the **tokenizer** with the **argument truncation=True**. This will ensure that an input **longer** that what the model selected can handle will be **truncated to the maximum length accepted by the model**. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
      ],
      "metadata": {
        "id": "8NYdCYfgNRUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\n",
        "\n",
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "\n",
        "source_lang = \"ur\"\n",
        "target_lang = \"en\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Getting Input and target\n",
        "    \"\"\"\n",
        "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "OZb1OI2BL0_R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_function(final_dataset['train'][:2])"
      ],
      "metadata": {
        "id": "D3pz5QinL1B6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c14aa2-503e-4c68-dce5-f286cd02f70c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[31585, 0], [349, 412, 0]], 'attention_mask': [[1, 1], [1, 1, 1]], 'labels': [[16918, 5, 0], [5569, 67, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **apply** this function on **all** the pairs of sentences in our dataset, we just use the **map** method of our **dataset** object we created earlier. This will **apply the function on all** the elements of all the splits in dataset, so our **training, validation and testing data** will be **preprocessed** in one single command"
      ],
      "metadata": {
        "id": "eEHe-hchN_aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = final_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "f7nA7y0NOPkR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "a28cb58fdcc14bcfa6573954af5e3c5d",
            "2912a6a3a7244d979a45178e24d1853a",
            "f6233c7a2311425da61e0dca6f0120f8",
            "733c7960da92415589df4d9591a3ca94",
            "050171291cb74f88b27a478f52f87363",
            "a69220d6922342109b7091f9f2525cf3",
            "a3ff8fb2eb6749b0aa7cc2d7911e7308",
            "9cee1c8a2bc54f24b118b7f9eef3db12",
            "1059f51016504bc9abae046cfa239e6a",
            "377dcd4afc8c457887fd0a2f4b56f0ce",
            "3a5b238bb3ca49dc936c5b9d3faaa5ce",
            "ad80f403b60040d891582ea164ab1d48",
            "9b080c3febf241b9893bce9a288ece8c",
            "bdb3c3a5dc6942a6988b982f9ce52729",
            "4d0404dcb07642b283a413e570f2d983",
            "59111ef992694e158c530f06d4c17b2c",
            "28d8dd64bf0a414b84051088de39deb5",
            "808a129dbf5342e3b2a6922ffa85e0d3",
            "f0cda1b1bf93401891e7017252165694",
            "c715da8624f34520869f7657c3c71ef2",
            "8a8da6e086494939b2311596579a78d9",
            "db21854fd98a44d4bfeb892660ad7d5c",
            "64434a20169b4c98b2a6bae5fe0cdfdf",
            "501fcd0e4555487095abcb592511683c",
            "7b4904586b6849a29cf19ac3b086b508",
            "22ef9615e7534e6ebb3a95daa0c3ac1d",
            "e6010267999843d19f2af39acc8b3fd4",
            "ec800871c5ac4351b64534f4f53bcbf4",
            "e2c84d4eb26b4954842b511f7d0125ce",
            "55d18bc23a6c4fdd8e2d4e0b6940f2b6",
            "da29f0bccf85496e86e97f455d012eb1",
            "6acbb36f71d6479db2b3085c0e9547d8",
            "d0dca114fde94abaa689f9ea06c8f005"
          ]
        },
        "outputId": "2a5fb251-8a0c-4f44-c6ca-2a66d6df123c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a28cb58fdcc14bcfa6573954af5e3c5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad80f403b60040d891582ea164ab1d48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64434a20169b4c98b2a6bae5fe0cdfdf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model\n",
        "Now that our data is ready, we can **download the pretrained** model and fine-tune it. Since our task is of the **sequence-to-sequence** kind, we use the **AutoModelForSeq2SeqLM** class. Like with the tokenizer, the from_pretrained method will download and cache the model for us."
      ],
      "metadata": {
        "id": "fXbeUUloN_zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "wcDrAGKbWfBQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model"
      ],
      "metadata": {
        "id": "lK5UMQkZXXaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(my_dir+\"save_model\")"
      ],
      "metadata": {
        "id": "5ttW5jmPXWW9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model from Save Directory"
      ],
      "metadata": {
        "id": "mTvi_zRNcRJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained('save_model')"
      ],
      "metadata": {
        "id": "G0ZiwV4CcK8a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **instantiate** a **Seq2SeqTrainer**, we will need to define **three** more things. The most important is the **Seq2SeqTrainingArguments**, which is a class that contains all the **attributes to customize the training**. It requires one **folder name**, which will be used to save the checkpoints of the model, and all other arguments are optional:"
      ],
      "metadata": {
        "id": "hOn6e4xTZtI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "print(\"Model name:\",model_name)\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=20,\n",
        "    predict_with_generate=True\n",
        ")"
      ],
      "metadata": {
        "id": "EHi74wP5Z_CR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c51908-1569-48fa-b515-c06a4a25c25d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name: opus-mt-ur-en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "id": "twlIOxf3Z_a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de703f63-dd80-4e75-a99a-6632fd21eed5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTrainingArguments(output_dir='opus-mt-ur-en-finetuned-ur-to-en', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, learning_rate=2e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=20, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='opus-mt-ur-en-finetuned-ur-to-en/runs/Dec23_17-47-29_aa60a29d35e0', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=3, save_safetensors=True, save_on_each_node=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, past_index=-1, run_name='opus-mt-ur-en-finetuned-ur-to-en', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, hub_always_push=False, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, split_batches=False, include_tokens_per_second=False, neftune_noise_alpha=None, sortish_sampler=False, predict_with_generate=True, generation_max_length=None, generation_num_beams=None, generation_config=None)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we **set** the **evaluation** to be done at the **end of each epoch**, tweak the learning rate, use the **batch_size** defined at the top of the cell and customize the weight decay. Since the **Seq2SeqTrainer** will **save** the **model** regularly and our dataset is quite large, we tell it to make** three saves maximum**. Lastly, we use the **predict_with_generate** option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
        "\n",
        "Model will **save** under **{model_name}-finetuned-{source_lang}-to-{target_lang}** directory\n",
        "\n",
        "Then, we need a special kind of **data collator**, which will not only **pad** the **inputs** to the **maximum length** in the batch, but also the **labels**:"
      ],
      "metadata": {
        "id": "PbpBCh4Sa4Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "_6XyXYKKcN0T"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last thing to define for our **Seq2SeqTrainer** is **how to compute the metrics** from the **predictions**. We need to define a function for this, which will just use the **metric** we loaded earlier, and we have to do a bit of **pre-processing to decode the predictions into texts**"
      ],
      "metadata": {
        "id": "w42ASTbucdK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions = decoded_preds, references = decoded_labels)\n",
        "\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "VHQNv35sXqf_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we just need to pass all of this along with our datasets to the Seq2SeqTrainer:"
      ],
      "metadata": {
        "id": "5T0ncMZIOAIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset = tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized_datasets[\"validation\"],\n",
        "    data_collator = data_collator,\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics = compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "kk_CGC2edbhy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now finetune our model by just calling the train method:"
      ],
      "metadata": {
        "id": "RdSFg0itOAMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "F6lZ439WNzvY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "0d3ff5ac-75c8-43af-85e6-5908474eab64"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1260/1260 1:20:46, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.844176</td>\n",
              "      <td>20.894200</td>\n",
              "      <td>11.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.856031</td>\n",
              "      <td>20.552600</td>\n",
              "      <td>11.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.875082</td>\n",
              "      <td>19.975500</td>\n",
              "      <td>11.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.920830</td>\n",
              "      <td>21.512500</td>\n",
              "      <td>11.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.946952</td>\n",
              "      <td>21.512700</td>\n",
              "      <td>11.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.984723</td>\n",
              "      <td>20.375600</td>\n",
              "      <td>11.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.024149</td>\n",
              "      <td>19.510700</td>\n",
              "      <td>11.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.061152</td>\n",
              "      <td>21.012000</td>\n",
              "      <td>11.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.093473</td>\n",
              "      <td>20.179700</td>\n",
              "      <td>11.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.128457</td>\n",
              "      <td>20.273600</td>\n",
              "      <td>11.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.160689</td>\n",
              "      <td>20.656200</td>\n",
              "      <td>11.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.192287</td>\n",
              "      <td>20.806300</td>\n",
              "      <td>11.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.205931</td>\n",
              "      <td>20.406100</td>\n",
              "      <td>11.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.220076</td>\n",
              "      <td>19.650800</td>\n",
              "      <td>11.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>2.243361</td>\n",
              "      <td>19.048200</td>\n",
              "      <td>11.220000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.231700</td>\n",
              "      <td>2.251168</td>\n",
              "      <td>18.580500</td>\n",
              "      <td>11.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.231700</td>\n",
              "      <td>2.259391</td>\n",
              "      <td>19.054500</td>\n",
              "      <td>11.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.231700</td>\n",
              "      <td>2.270887</td>\n",
              "      <td>19.261600</td>\n",
              "      <td>11.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.231700</td>\n",
              "      <td>2.277000</td>\n",
              "      <td>19.266400</td>\n",
              "      <td>11.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.231700</td>\n",
              "      <td>2.279181</td>\n",
              "      <td>19.276100</td>\n",
              "      <td>11.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1260, training_loss=0.46416334727453806, metrics={'train_runtime': 4856.2511, 'train_samples_per_second': 4.118, 'train_steps_per_second': 0.259, 'total_flos': 70406903955456.0, 'train_loss': 0.46416334727453806, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "M5FV6N1JjeG1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('opus-mt-ur-en-finetuned-ur-to-en'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "ZSPbTW_Sdqnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b497fa8-14bc-4729-81f9-a6edaddf6cd7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opus-mt-ur-en-finetuned-ur-to-en/training_args.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/generation_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/special_tokens_map.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/model.safetensors\n",
            "opus-mt-ur-en-finetuned-ur-to-en/source.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/tokenizer_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/target.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/vocab.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/rng_state.pth\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/training_args.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/generation_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/special_tokens_map.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/model.safetensors\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/source.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/scheduler.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/optimizer.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/trainer_state.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/tokenizer_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/target.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/vocab.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/rng_state.pth\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/training_args.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/generation_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/special_tokens_map.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/model.safetensors\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/source.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/scheduler.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/optimizer.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/trainer_state.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/tokenizer_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/target.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/vocab.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/runs/Dec23_17-47-29_aa60a29d35e0/events.out.tfevents.1703353650.aa60a29d35e0.8449.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our fine tuned model already saved under opus-mt-ur-en-finetuned-ur-to-en/\n",
        "\n",
        "Load the model and translate some text from english to romanian"
      ],
      "metadata": {
        "id": "nXBgZytef2rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "our fine tune model is doing far better than pre-trained model and close to google translator"
      ],
      "metadata": {
        "id": "ne-XERwxf3sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Model name for Urdu to English translation\n",
        "model_name = 'opus-mt-ur-en-finetuned-ur-to-en'\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "# Get input from the user\n",
        "user_input = input(\"Enter the sentence to translate from Urdu to English: \")\n",
        "\n",
        "# Translate the user input\n",
        "translated = model.generate(**tokenizer([user_input], return_tensors=\"pt\", padding=True))\n",
        "\n",
        "# Decode the translated output\n",
        "result = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "\n",
        "# Print the result\n",
        "print(\"Original Urdu sentence:\", user_input)\n",
        "print(\"Translated English sentence:\", result[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLTqfmGUZyoT",
        "outputId": "ad6ac810-fe9d-4a84-a2ec-6cfc6e6405d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the sentence to translate from Urdu to English: آپ کيا کررہے ہو؟\n",
            "Original Urdu sentence: آپ کيا کررہے ہو؟\n",
            "Translated English sentence: What are you doing?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7M1kGrnwMhJ",
        "outputId": "cd848270-849d-40e1-86b1-d4b3477dea6e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "from googletrans import Translator\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when the app is run\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "# Define Flask route\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "    translated_text = None\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        try:\n",
        "            input_text = request.form['input_text']\n",
        "            if input_text:\n",
        "                # Translate the input text from Urdu to English\n",
        "                translated_text = translator.translate(input_text, src='ur', dest='en').text\n",
        "            else:\n",
        "                translated_text = \"Type a sentence to translate\"\n",
        "        except Exception as e:\n",
        "            return render_template('error.html', error_message=str(e))\n",
        "\n",
        "    return render_template('index.html', translated_text=translated_text)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zClo84Ohqyf-",
        "outputId": "1c682d4a-61b5-4377-ac12-36c56b7b4d9a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://d4d7-34-150-170-188.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Dec/2023 22:30:49] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Dec/2023 22:30:50] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Dec/2023 22:30:59] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Dec/2023 22:31:47] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Dec/2023 22:32:34] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Dec/2023 22:32:35] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86YgIomAw3bT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}